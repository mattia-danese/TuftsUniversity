{"authors": ["Adam Satariano", "Paul Mozur"], "date_download": "2023-03-28 18:40:05", "date_modify": "2023-03-28 18:40:05", "date_publish": "2023-02-07 10:00:35", "description": "For the first time, A.I.-generated personas, often used for corporate trainings, were detected in a state-aligned information campaign — opening a new chapter in online manipulation.", "filename": "2023_02_07_technology_artificial-intelligence-training-deepfake_1680028805.html", "image_url": "https://static01.nyt.com/images/2023/02/01/video/01vid-deepfake-disinfo-woman-split-COVER/01vid-deepfake-disinfo-woman-split-COVER-facebookJumbo-v2.png", "language": "en", "localpath": "/home/mwaldrich/news-please-repo//data/2023/03/28/nytimes.com/2023_02_07_technology_artificial-intelligence-training-deepfake_1680028805.html", "title": "How Deepfake Videos Are Used to Spread Disinformation", "title_page": "How Deepfake Videos Are Used to Spread Disinformation - The New York Times", "title_rss": "NULL", "source_domain": "nytimes.com", "maintext": "But something was off. Their voices were stilted and failed to sync with the movement of their mouths. Their faces had a pixelated, video-game quality and their hair appeared unnaturally plastered to the head. The captions were filled with grammatical mistakes.\nThe two broadcasters, purportedly anchors for a news outlet called Wolf News, are not real people. They are computer-generated avatars created by artificial intelligence software. And late last year, videos of them were distributed by pro-China bot accounts on Facebook and Twitter, in the first known instance of “deepfake” video technology being used to create fictitious people as part of a state-aligned information campaign.\n“This is the first time we’ve seen this in the wild,” said Jack Stubbs, the vice president of intelligence at Graphika, a research firm that studies disinformation. Graphika discovered the pro-China campaign, which appeared intended to promote the interests of the Chinese Communist Party and undercut the United States for English-speaking viewers.\n“Deepfake” technology, which has progressed steadily for nearly a decade, has the ability to create talking digital puppets. The A.I. software is sometimes used to distort public figures, like a video that circulated on social media last year falsely showing Volodymyr Zelensky, the president of Ukraine, announcing a surrender. But the software can also create characters out of whole cloth, going beyond traditional editing software and expensive special effects tools used by Hollywood, blurring the line between fact and fiction to an extraordinary degree.\nWith few laws to manage the spread of the technology, disinformation experts have long warned that deepfake videos could further sever people’s ability to discern reality from forgeries online, potentially being misused to set off unrest or incept a political scandal. Those predictions have now become reality.", "url": "https://www.nytimes.com/2023/02/07/technology/artificial-intelligence-training-deepfake.html"}